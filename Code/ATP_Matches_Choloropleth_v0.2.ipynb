{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ATP Matches Choloropleth v0.2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOTp-WhFc7AM",
        "outputId": "64d44d3e-a391-42b1-eb89-ecb6c7781a38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        }
      },
      "source": [
        "!pip install geopandas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting geopandas\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/a4/e66aafbefcbb717813bf3a355c8c4fc3ed04ea1dd7feb2920f2f4f868921/geopandas-0.8.1-py2.py3-none-any.whl (962kB)\n",
            "\u001b[K     |████████████████████████████████| 972kB 2.8MB/s \n",
            "\u001b[?25hCollecting fiona\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/8b/e8b2c11bed5373c8e98edb85ce891b09aa1f4210fd451d0fb3696b7695a2/Fiona-1.8.17-cp36-cp36m-manylinux1_x86_64.whl (14.8MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8MB 309kB/s \n",
            "\u001b[?25hRequirement already satisfied: shapely in /usr/local/lib/python3.6/dist-packages (from geopandas) (1.7.1)\n",
            "Collecting pyproj>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/c3/071e080230ac4b6c64f1a2e2f9161c9737a2bc7b683d2c90b024825000c0/pyproj-2.6.1.post1-cp36-cp36m-manylinux2010_x86_64.whl (10.9MB)\n",
            "\u001b[K     |████████████████████████████████| 10.9MB 42.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from geopandas) (1.1.2)\n",
            "Requirement already satisfied: click<8,>=4.0 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (7.1.2)\n",
            "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (20.2.0)\n",
            "Collecting click-plugins>=1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/da/824b92d9942f4e472702488857914bdd50f73021efea15b4cad9aca8ecef/click_plugins-1.1.1-py2.py3-none-any.whl\n",
            "Collecting cligj>=0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/ba/06/e3440b1f2dc802d35f329f299ba96153e9fcbfdef75e17f4b61f79430c6a/cligj-0.7.0-py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (1.15.0)\n",
            "Collecting munch\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (1.18.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (2018.9)\n",
            "Installing collected packages: click-plugins, cligj, munch, fiona, pyproj, geopandas\n",
            "Successfully installed click-plugins-1.1.1 cligj-0.7.0 fiona-1.8.17 geopandas-0.8.1 munch-2.5.0 pyproj-2.6.1.post1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2htDaF0PbuSR"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u64OE7PYbuSt",
        "outputId": "e49982e4-312c-42b7-8ff2-531ce6e41f14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "\n",
        "alldata = []\n",
        "directory = 'dataset/' #dataset directory\n",
        "for filename in os.listdir(directory):\n",
        "    if filename.endswith(\".csv\") and filename.startswith(\"atp\"):\n",
        "        print(os.path.join(directory, filename))\n",
        "        year= filename.split(\"_\")[2].split(\".\")[0]  #Getting year from filename to add in dataframe in Year column\n",
        "        file1 = open(os.path.join(directory, filename), 'r')\n",
        "        Lines = file1.readlines() \n",
        "        file_list = []\n",
        "        for line in Lines: \n",
        "            list_lin = line.rstrip(\"\\n\").rstrip(',').split(\",\") #Stripping out additional comma at the end of line\n",
        "            file_list.append(list_lin) #appending cleaned lies to a temp list \n",
        "        tempdf=pd.DataFrame(file_list[1:],columns=file_list[0]) #converting temp list (excluding first line as headings) into dataframe\n",
        "        tempdf['year']= int(year) #Adding year into dataframe columns\n",
        "        alldata.append(tempdf) #adding dataframe to a list\n",
        "    else:\n",
        "        continue\n",
        "tennis_df = pd.concat(alldata) #Concatenating all data frame\n",
        "tennis_df.reset_index(drop=True,inplace=True) #Resetting index\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset/atp_matches_2010.csv\n",
            "dataset/atp_matches_2002.csv\n",
            "dataset/atp_matches_2016.csv\n",
            "dataset/atp_matches_2014.csv\n",
            "dataset/atp_matches_2000.csv\n",
            "dataset/atp_matches_2006.csv\n",
            "dataset/atp_matches_2008.csv\n",
            "dataset/atp_matches_2001.csv\n",
            "dataset/atp_matches_2017.csv\n",
            "dataset/atp_matches_2003.csv\n",
            "dataset/atp_matches_2007.csv\n",
            "dataset/atp_matches_2009.csv\n",
            "dataset/atp_matches_2015.csv\n",
            "dataset/atp_matches_2012.csv\n",
            "dataset/atp_matches_2013.csv\n",
            "dataset/atp_matches_2005.csv\n",
            "dataset/atp_matches_2011.csv\n",
            "dataset/atp_matches_2004.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujvAdiEybuTM",
        "outputId": "52f3f346-1688-4cc1-a4d5-ee71e21d296e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        }
      },
      "source": [
        "tennis_df.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tourney_id</th>\n",
              "      <th>tourney_name</th>\n",
              "      <th>surface</th>\n",
              "      <th>draw_size</th>\n",
              "      <th>tourney_level</th>\n",
              "      <th>tourney_date</th>\n",
              "      <th>match_num</th>\n",
              "      <th>winner_id</th>\n",
              "      <th>winner_seed</th>\n",
              "      <th>winner_entry</th>\n",
              "      <th>winner_name</th>\n",
              "      <th>winner_hand</th>\n",
              "      <th>winner_ht</th>\n",
              "      <th>winner_ioc</th>\n",
              "      <th>winner_age</th>\n",
              "      <th>winner_rank</th>\n",
              "      <th>winner_rank_points</th>\n",
              "      <th>loser_id</th>\n",
              "      <th>loser_seed</th>\n",
              "      <th>loser_entry</th>\n",
              "      <th>loser_name</th>\n",
              "      <th>loser_hand</th>\n",
              "      <th>loser_ht</th>\n",
              "      <th>loser_ioc</th>\n",
              "      <th>loser_age</th>\n",
              "      <th>loser_rank</th>\n",
              "      <th>loser_rank_points</th>\n",
              "      <th>score</th>\n",
              "      <th>best_of</th>\n",
              "      <th>round</th>\n",
              "      <th>minutes</th>\n",
              "      <th>w_ace</th>\n",
              "      <th>w_df</th>\n",
              "      <th>w_svpt</th>\n",
              "      <th>w_1stIn</th>\n",
              "      <th>w_1stWon</th>\n",
              "      <th>w_2ndWon</th>\n",
              "      <th>w_SvGms</th>\n",
              "      <th>w_bpSaved</th>\n",
              "      <th>w_bpFaced</th>\n",
              "      <th>l_ace</th>\n",
              "      <th>l_df</th>\n",
              "      <th>l_svpt</th>\n",
              "      <th>l_1stIn</th>\n",
              "      <th>l_1stWon</th>\n",
              "      <th>l_2ndWon</th>\n",
              "      <th>l_SvGms</th>\n",
              "      <th>l_bpSaved</th>\n",
              "      <th>l_bpFaced</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>53566</th>\n",
              "      <td>2004-D082</td>\n",
              "      <td>Davis Cup WG PO: ROU vs CAN</td>\n",
              "      <td>Clay</td>\n",
              "      <td>4</td>\n",
              "      <td>D</td>\n",
              "      <td>20040924</td>\n",
              "      <td>4</td>\n",
              "      <td>104181</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Victor Ionita</td>\n",
              "      <td>R</td>\n",
              "      <td>185</td>\n",
              "      <td>ROU</td>\n",
              "      <td>21.363449692</td>\n",
              "      <td>216</td>\n",
              "      <td>176</td>\n",
              "      <td>103225</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Simon Larose</td>\n",
              "      <td>R</td>\n",
              "      <td>190</td>\n",
              "      <td>CAN</td>\n",
              "      <td>26.2313483915</td>\n",
              "      <td>301</td>\n",
              "      <td>105</td>\n",
              "      <td>4-2 RET</td>\n",
              "      <td>5</td>\n",
              "      <td>RR</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>2004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53567</th>\n",
              "      <td>2004-D083</td>\n",
              "      <td>Davis Cup WG PO: RUS vs THA</td>\n",
              "      <td>Clay</td>\n",
              "      <td>4</td>\n",
              "      <td>D</td>\n",
              "      <td>20040924</td>\n",
              "      <td>1</td>\n",
              "      <td>104214</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Igor Andreev</td>\n",
              "      <td>R</td>\n",
              "      <td>185</td>\n",
              "      <td>RUS</td>\n",
              "      <td>21.1882272416</td>\n",
              "      <td>40</td>\n",
              "      <td>826</td>\n",
              "      <td>103387</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Paradorn Srichaphan</td>\n",
              "      <td>R</td>\n",
              "      <td>185</td>\n",
              "      <td>THA</td>\n",
              "      <td>25.2703627652</td>\n",
              "      <td>20</td>\n",
              "      <td>1280</td>\n",
              "      <td>7-5 6-2 6-4</td>\n",
              "      <td>5</td>\n",
              "      <td>RR</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>2004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53568</th>\n",
              "      <td>2004-D083</td>\n",
              "      <td>Davis Cup WG PO: RUS vs THA</td>\n",
              "      <td>Clay</td>\n",
              "      <td>4</td>\n",
              "      <td>D</td>\n",
              "      <td>20040924</td>\n",
              "      <td>2</td>\n",
              "      <td>103498</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Marat Safin</td>\n",
              "      <td>R</td>\n",
              "      <td>193</td>\n",
              "      <td>RUS</td>\n",
              "      <td>24.6488706366</td>\n",
              "      <td>9</td>\n",
              "      <td>1760</td>\n",
              "      <td>103821</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Danai Udomchoke</td>\n",
              "      <td>R</td>\n",
              "      <td>173</td>\n",
              "      <td>THA</td>\n",
              "      <td>23.1101984942</td>\n",
              "      <td>163</td>\n",
              "      <td>245</td>\n",
              "      <td>6-4 6-1 6-2</td>\n",
              "      <td>5</td>\n",
              "      <td>RR</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>2004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53569</th>\n",
              "      <td>2004-D083</td>\n",
              "      <td>Davis Cup WG PO: RUS vs THA</td>\n",
              "      <td>Clay</td>\n",
              "      <td>4</td>\n",
              "      <td>D</td>\n",
              "      <td>20040924</td>\n",
              "      <td>3</td>\n",
              "      <td>103786</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Nikolay Davydenko</td>\n",
              "      <td>R</td>\n",
              "      <td>178</td>\n",
              "      <td>RUS</td>\n",
              "      <td>23.3018480493</td>\n",
              "      <td>45</td>\n",
              "      <td>779</td>\n",
              "      <td>103921</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Sonchat Ratiwatana</td>\n",
              "      <td>R</td>\n",
              "      <td>175</td>\n",
              "      <td>THA</td>\n",
              "      <td>22.6584531143</td>\n",
              "      <td>736</td>\n",
              "      <td>17</td>\n",
              "      <td>6-2 6-0</td>\n",
              "      <td>3</td>\n",
              "      <td>RR</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>2004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53570</th>\n",
              "      <td>2004-D083</td>\n",
              "      <td>Davis Cup WG PO: RUS vs THA</td>\n",
              "      <td>Clay</td>\n",
              "      <td>4</td>\n",
              "      <td>D</td>\n",
              "      <td>20040924</td>\n",
              "      <td>4</td>\n",
              "      <td>104022</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Mikhail Youzhny</td>\n",
              "      <td>R</td>\n",
              "      <td>183</td>\n",
              "      <td>RUS</td>\n",
              "      <td>22.2395619439</td>\n",
              "      <td>33</td>\n",
              "      <td>1005</td>\n",
              "      <td>103920</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Sanchai Ratiwatana</td>\n",
              "      <td>R</td>\n",
              "      <td>175</td>\n",
              "      <td>THA</td>\n",
              "      <td>22.6584531143</td>\n",
              "      <td>904</td>\n",
              "      <td>8</td>\n",
              "      <td>6-4 6-2</td>\n",
              "      <td>3</td>\n",
              "      <td>RR</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>2004</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      tourney_id                 tourney_name surface  ... l_bpSaved l_bpFaced  year\n",
              "53566  2004-D082  Davis Cup WG PO: ROU vs CAN    Clay  ...      None      None  2004\n",
              "53567  2004-D083  Davis Cup WG PO: RUS vs THA    Clay  ...      None      None  2004\n",
              "53568  2004-D083  Davis Cup WG PO: RUS vs THA    Clay  ...      None      None  2004\n",
              "53569  2004-D083  Davis Cup WG PO: RUS vs THA    Clay  ...      None      None  2004\n",
              "53570  2004-D083  Davis Cup WG PO: RUS vs THA    Clay  ...      None      None  2004\n",
              "\n",
              "[5 rows x 50 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhL3UPpObuTa",
        "outputId": "fd8e31e4-762c-4807-f7ab-10decc2d11f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "# checking if all csvs have same columns\n",
        "'''prev_list = ''\n",
        "for x in alldata:\n",
        "    if prev_list == '':\n",
        "        prev_list=str(x.columns)\n",
        "    else:\n",
        "        if str(x.columns) == prev_list:\n",
        "            print(\"matches\")\n",
        "            prev_list=str(x.columns)\n",
        "        else:\n",
        "            print(\"not macthes\",str(x.columns))\n",
        "            break'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'prev_list = \\'\\'\\nfor x in alldata:\\n    if prev_list == \\'\\':\\n        prev_list=str(x.columns)\\n    else:\\n        if str(x.columns) == prev_list:\\n            print(\"matches\")\\n            prev_list=str(x.columns)\\n        else:\\n            print(\"not macthes\",str(x.columns))\\n            break'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsK2O9F-buTk",
        "outputId": "61bbfa50-0b17-4bfb-e496-2df8deb2c079",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "#Missing values in winne_ioc columns\n",
        "sum(tennis_df['winner_ioc'].isna())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "63"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHqWtZahbuTv",
        "outputId": "96243ecd-08c9-48f0-8dab-3b52a99bfd13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "len(tennis_df['winner_ioc'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53571"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiaLJo1rbuT5",
        "outputId": "b5ba9779-c8f3-439f-9b33-6c6a5361919b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "tennis_df[['year','winner_ioc']].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>winner_ioc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010</td>\n",
              "      <td>GER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010</td>\n",
              "      <td>USA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010</td>\n",
              "      <td>ARG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010</td>\n",
              "      <td>SUI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010</td>\n",
              "      <td>NZL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   year winner_ioc\n",
              "0  2010        GER\n",
              "1  2010        USA\n",
              "2  2010        ARG\n",
              "3  2010        SUI\n",
              "4  2010        NZL"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_nPrSbvbuUB",
        "outputId": "4d128b66-4426-4007-d462-8cd4d1eb823e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "print(\"Unique countries\",len(set(list(tennis_df['winner_ioc']))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique countries 105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd8zFppPbuUK",
        "outputId": "da0374f3-d25d-4f4f-927b-77582e999bf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#viewing sample countries\n",
        "for x in alldata:\n",
        "    print(np.unique(list(x['year'])))\n",
        "    print(list(x['winner_ioc'].head()))\n",
        "    print(\"-------------------------------\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2010]\n",
            "['GER', 'USA', 'ARG', 'SUI', 'NZL']\n",
            "-------------------------------\n",
            "[2002]\n",
            "['USA', 'KOR', 'FRA', 'AUT', 'USA']\n",
            "-------------------------------\n",
            "[2016]\n",
            "['CAN', 'SUI', 'CAN', 'SUI', 'AUT']\n",
            "-------------------------------\n",
            "[2014]\n",
            "['USA', 'COL', 'ESP', 'USA', 'TPE']\n",
            "-------------------------------\n",
            "[2000]\n",
            "['FRA', 'CHI', 'THA', 'NED', 'AUS']\n",
            "-------------------------------\n",
            "[2006]\n",
            "['SUI', 'COL', 'BLR', 'CHI', 'CZE']\n",
            "-------------------------------\n",
            "[2008]\n",
            "['FRA', 'RUS', 'FRA', 'ESP', 'FRA']\n",
            "-------------------------------\n",
            "[2001]\n",
            "['BRA', 'GBR', 'AUT', 'GER', 'FRA']\n",
            "-------------------------------\n",
            "[2017]\n",
            "['BUL', 'BUL', 'JPN', 'CAN', 'BUL']\n",
            "-------------------------------\n",
            "[2003]\n",
            "['BEL', 'GER', 'CZE', 'GER', 'CZE']\n",
            "-------------------------------\n",
            "[2007]\n",
            "['ROU', 'FIN', 'GER', 'FRA', 'CZE']\n",
            "-------------------------------\n",
            "[2009]\n",
            "['FRA', 'AUT', 'FRA', 'AUS', 'FRA']\n",
            "-------------------------------\n",
            "[2015]\n",
            "['SUI', 'JPN', 'USA', 'POR', 'FRA']\n",
            "-------------------------------\n",
            "[2012]\n",
            "['USA', 'LTU', 'BEL', 'FRA', 'GER']\n",
            "-------------------------------\n",
            "[2013]\n",
            "['ARG', 'ARG', 'ESP', 'ESP', 'NED']\n",
            "-------------------------------\n",
            "[2005]\n",
            "['ESP', 'SUI', 'FRA', 'DEN', 'FRA']\n",
            "-------------------------------\n",
            "[2011]\n",
            "['GER', 'COL', 'RUS', 'FRA', 'BEL']\n",
            "-------------------------------\n",
            "[2004]\n",
            "['SVK', 'ESP', 'ARG', 'ESP', 'FRA']\n",
            "-------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "166phoUJV9aI"
      },
      "source": [
        "# Winner Count per country per year"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPqSRoj2buUj"
      },
      "source": [
        "winning_country_year_df=[] #We will have seperate dataframe for every year, all dataframe to be stored in this list\n",
        "year_key = {}\n",
        "count = 0\n",
        "\n",
        "for year in set(list(tennis_df['year'])): #Looping through countries\n",
        "    tmp_list = []\n",
        "    for country in set(list(tennis_df[tennis_df['year'] == year]['winner_ioc'])): #Looping through years\n",
        "      if country != None:\n",
        "        tmp_list.append([country,len(tennis_df[(tennis_df['winner_ioc'] == country) & (tennis_df['year'] == year)])]) #Addding country name and number of winners\n",
        "    winning_country_year_df.append(pd.DataFrame(tmp_list,columns=['Country','Winner_Count'])) #converting to a dataframe and storing to list\n",
        "    year_key[count] = year  #Creating index to year dictionary for future reference\n",
        "    count+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hGWRCNpbuU8"
      },
      "source": [
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import geopandas as gpd #For chrolopleth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnFCb6tObuVF",
        "outputId": "02a13b66-6bf2-4100-ab0f-cf9b7b6aa4c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "import geopandas as gpd\n",
        "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))  #This file has geography information\n",
        "print(world.head())\n",
        "world['new_name']=world['name'].str.upper().apply(lambda y: y[0:3])  #creating a new column with first 3 letters of country name"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     pop_est  ...                                           geometry\n",
            "0     920938  ...  MULTIPOLYGON (((180.00000 -16.06713, 180.00000...\n",
            "1   53950935  ...  POLYGON ((33.90371 -0.95000, 34.07262 -1.05982...\n",
            "2     603253  ...  POLYGON ((-8.66559 27.65643, -8.66512 27.58948...\n",
            "3   35623680  ...  MULTIPOLYGON (((-122.84000 49.00000, -122.9742...\n",
            "4  326625791  ...  MULTIPOLYGON (((-122.84000 49.00000, -120.0000...\n",
            "\n",
            "[5 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zjydy8BRSrxB"
      },
      "source": [
        "world.to_csv(\"/content/ATP_matches_Visualisation/dataset/world.csv\") #Downloading for analysis via excel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrueyDUqVOCl"
      },
      "source": [
        "#\n",
        "winning_country_year_geometry_df = [] #List to hold dataframe for every year. Each dataframe will be an extension of world df with winner count as additional column\n",
        "\n",
        "#Below are some hard coded values to map with the ones in world dataframe\n",
        "#\n",
        "unavailable_Country_codes = [] #To save country codes which are not available\n",
        "\n",
        "#AHO belong to netherlands antilles, which is not available in world dataframe hence mapping it to USA\n",
        "#GUM belong to Guam, which is not available in world dataframe hence mapping it to USA\n",
        "#AND belong to Andorra, which is not available in world dataframe hence mapping it to spain\n",
        "#BAR belong to Barbados, which is not available in world dataframe hence mapping it to PRI\n",
        "#HKG belong to Hong Kong, which is not available in world dataframe hence mapping it to CHINA - CHN\n",
        "#MHL belong to Marshall Islands, which is not available in world dataframe hence mapping it to USA\n",
        "#SAM belong to Samoa, which is not available in world dataframe hence mapping it to USA\n",
        "#COK belong to cook islands, which is not available in world dataframe hence mapping it to NZL\n",
        "\n",
        "#Dictionary to map ATP country code to ISO country code for the ones which are tricky\n",
        "some_known_dict = {'INA':'IDN','PUR':'PRI','ESA':'EST','RSA':'ZAF','MAS':'MYS','NED':'NLD','TPE':'TWN','SUI':'CHE','AHO':'USA'\\\n",
        "                   ,'AND':'ESP','CRC':'CRI','GUM':'USA','HKG':'CHN','IRI':'IRN','MHL':'USA','SAM':'USA','BAR':'PRI','UAE':'ARE',\\\n",
        "                   'NGR':'NGA','COK':'NZL'}\n",
        "\n",
        "for e in range(len(winning_country_year_df)):\n",
        "  geom_col = []  #We want to create a new column which will have the iso_a3 country code for a given country\n",
        "  for each_count in list(winning_country_year_df[e]['Country']): #each_count is each_country\n",
        "    subsetdf = world[world['iso_a3'] == each_count] #Checking is the ATP country code is same as iso country code\n",
        "    if len(subsetdf) == 1:\n",
        "      geom_col.append(subsetdf.iloc[0]['iso_a3'])  #Appending the iso country code\n",
        "    else:\n",
        "      subsetdf = world[world['new_name'] == each_count]  #We created a new columns with the first 3 letters of every country. Checking to see if it matches ATP code\n",
        "      if len(subsetdf) > 0:\n",
        "        geom_col.append(subsetdf.iloc[0]['iso_a3']) #In case of a match, Appending its iso country code\n",
        "      else:\n",
        "        try:\n",
        "          subsetdf = world[world['iso_a3'] == some_known_dict[each_count]] #Else checking in out dictonary for the ATP country code\n",
        "          if len(subsetdf) > 0:\n",
        "            geom_col.append(some_known_dict[each_count])  #In case of a match appending its iso_a3 country code\n",
        "          else:\n",
        "            print(each_count,\" could not be found\")  #Else printing to check manually\n",
        "            unavailable_Country_codes.append(each_count)\n",
        "            print(e)\n",
        "            geom_col.append(\"\")\n",
        "        except:  #Else printing to check manually\n",
        "          print(each_count,\" could not be found\")\n",
        "          unavailable_Country_codes.append(each_count)\n",
        "          print(e)\n",
        "          geom_col.append(\"\")\n",
        "  winning_country_year_df[e]['matching_col'] = geom_col  #Appending the new column to the dataframe\n",
        "  tmp_world_df = world.merge(winning_country_year_df[e], how='left', left_on=\"iso_a3\", right_on=\"matching_col\")\n",
        "  tmp_world_df['Winner_Count'] = tmp_world_df['Winner_Count'].fillna(0)\n",
        "  winning_country_year_geometry_df.append(tmp_world_df) #Appending the winner count to the world dataframe using the newly created column and then appending them to a list\n",
        "unavailable_Country_codes =set(unavailable_Country_codes)\n",
        "if len(unavailable_Country_codes) > 0:\n",
        "  print(\"Unavailable country codes\",unavailable_Country_codes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCxdPZn4qOD0"
      },
      "source": [
        "# Choloropleth Animation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BStxd4yjUq9R"
      },
      "source": [
        "output_path = '/content/ATP_matches_Visualisation/maps'\n",
        "try:\n",
        "  os.mkdir(output_path)\n",
        "except:\n",
        "  print(\"unable to create output directory \"+output_path)\n",
        "\n",
        "images = []\n",
        "\n",
        "vmin, vmax = 0, 370\n",
        "for e in range(len(winning_country_year_geometry_df)):\n",
        "    \n",
        "    # create map, UDPATE: added plt.Normalize to keep the legend range the same for all maps\n",
        "    fig = winning_country_year_geometry_df[e].plot(column='Winner_Count', cmap='Blues', figsize=(10,10), linewidth=0.8, edgecolor='0.8', vmin=vmin, vmax=vmax,\n",
        "legend=True, norm=plt.Normalize(vmin=vmin, vmax=vmax), legend_kwds={'shrink': 0.5})\n",
        "    \n",
        "   \n",
        "    # remove axis of chart\n",
        "    fig.axis('off')\n",
        "    \n",
        "    # add a title\n",
        "    fig.set_title('Winners of ATP matches', \\\n",
        "              fontdict={'fontsize': '18',\n",
        "                         'fontweight' : '3'})\n",
        "    fig.annotate(year_key[e],\n",
        "            xy=(0.1, .35), xycoords='figure fraction',\n",
        "            horizontalalignment='left', verticalalignment='top',\n",
        "            fontsize=18)\n",
        "    # this will save the figure as a high-res png in the output path. you can also save as svg if you prefer.\n",
        "    filepath = os.path.join(output_path, str(year_key[e])+'_ATP_winners.png')\n",
        "    chart = fig.get_figure()\n",
        "    chart.savefig(filepath, dpi=300, transparent=True)\n",
        "\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "for e in range(len(winning_country_year_geometry_df)):\n",
        "  im = Image.open(os.path.join(output_path, str(year_key[e])+'_ATP_winners.png'))\n",
        "  images.append(im)\n",
        "\n",
        "# creating the GIF\n",
        "images[0].save(output_path+'/ATP_matches_winners.gif',\n",
        "               save_all=True, append_images=images[1:], optimize=True, duration=800, loop=0)\n",
        "\n",
        "#Standarding...........\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTKVHsUjbRcE"
      },
      "source": [
        "def show_gif(fname):\n",
        "    import base64\n",
        "    from IPython import display\n",
        "    with open(fname, 'rb') as fd:\n",
        "        b64 = base64.b64encode(fd.read()).decode('ascii')\n",
        "    return display.HTML(f'<img src=\"data:image/gif;base64,{b64}\" width=\"750\" align=\"center\" />')\n",
        "show_gif('/content/ATP_matches_Visualisation/maps/ATP_matches_winners.gif')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8FflcyhoBrE"
      },
      "source": [
        "# Loser Count Per Country"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lugYS_N1zrtN"
      },
      "source": [
        "winning_country_year_df=[] #We will have seperate dataframe for every year, all dataframe to be stored in this list\n",
        "year_key = {}\n",
        "count = 0\n",
        "\n",
        "for year in set(list(tennis_df['year'])): #Looping through countries\n",
        "    tmp_list = []\n",
        "    for country in set(list(tennis_df[tennis_df['year'] == year]['loser_ioc'])): #Looping through years\n",
        "      if country != None:\n",
        "        tmp_list.append([country,len(tennis_df[(tennis_df['loser_ioc'] == country) & (tennis_df['year'] == year)])]) #Addding country name and number of winners\n",
        "    winning_country_year_df.append(pd.DataFrame(tmp_list,columns=['Country','Winner_Count'])) #converting to a dataframe and storing to list\n",
        "    year_key[count] = year  #Creating index to year dictionary for future reference\n",
        "    count+=1\n",
        "\n",
        "#\n",
        "winning_country_year_geometry_df = [] #List to hold dataframe for every year. Each dataframe will be an extension of world df with winner count as additional column\n",
        "\n",
        "#Below are some hard coded values to map with the ones in world dataframe\n",
        "#\n",
        "unavailable_Country_codes = [] #To save country codes which are not available\n",
        "\n",
        "#AHO belong to netherlands antilles, which is not available in world dataframe hence mapping it to USA\n",
        "#GUM belong to Guam, which is not available in world dataframe hence mapping it to USA\n",
        "#AND belong to Andorra, which is not available in world dataframe hence mapping it to spain\n",
        "#BAR belong to Barbados, which is not available in world dataframe hence mapping it to PRI\n",
        "#HKG belong to Hong Kong, which is not available in world dataframe hence mapping it to CHINA - CHN\n",
        "#MHL belong to Marshall Islands, which is not available in world dataframe hence mapping it to USA\n",
        "#SAM belong to Samoa, which is not available in world dataframe hence mapping it to USA\n",
        "#COK belong to cook islands, which is not available in world dataframe hence mapping it to NZL\n",
        "\n",
        "#Dictionary to map ATP country code to ISO country code for the ones which are tricky\n",
        "some_known_dict = {'INA':'IDN','PUR':'PRI','ESA':'EST','RSA':'ZAF','MAS':'MYS','NED':'NLD','TPE':'TWN','SUI':'CHE','AHO':'USA'\\\n",
        "                   ,'AND':'ESP','CRC':'CRI','GUM':'USA','HKG':'CHN','IRI':'IRN','MHL':'USA','SAM':'USA','BAR':'PRI','UAE':'ARE',\\\n",
        "                   'NGR':'NGA','COK':'NZL'}\n",
        "\n",
        "for e in range(len(winning_country_year_df)):\n",
        "  geom_col = []  #We want to create a new column which will have the iso_a3 country code for a given country\n",
        "  for each_count in list(winning_country_year_df[e]['Country']): #each_count is each_country\n",
        "    subsetdf = world[world['iso_a3'] == each_count] #Checking is the ATP country code is same as iso country code\n",
        "    if len(subsetdf) == 1:\n",
        "      geom_col.append(subsetdf.iloc[0]['iso_a3'])  #Appending the iso country code\n",
        "    else:\n",
        "      subsetdf = world[world['new_name'] == each_count]  #We created a new columns with the first 3 letters of every country. Checking to see if it matches ATP code\n",
        "      if len(subsetdf) > 0:\n",
        "        geom_col.append(subsetdf.iloc[0]['iso_a3']) #In case of a match, Appending its iso country code\n",
        "      else:\n",
        "        try:\n",
        "          subsetdf = world[world['iso_a3'] == some_known_dict[each_count]] #Else checking in out dictonary for the ATP country code\n",
        "          if len(subsetdf) > 0:\n",
        "            geom_col.append(some_known_dict[each_count])  #In case of a match appending its iso_a3 country code\n",
        "          else:\n",
        "            print(each_count,\" could not be found\")  #Else printing to check manually\n",
        "            unavailable_Country_codes.append(each_count)\n",
        "            print(e)\n",
        "            geom_col.append(\"\")\n",
        "        except:  #Else printing to check manually\n",
        "          print(each_count,\" could not be found\")\n",
        "          unavailable_Country_codes.append(each_count)\n",
        "          print(e)\n",
        "          geom_col.append(\"\")\n",
        "  winning_country_year_df[e]['matching_col'] = geom_col  #Appending the new column to the dataframe\n",
        "  tmp_world_df = world.merge(winning_country_year_df[e], how='left', left_on=\"iso_a3\", right_on=\"matching_col\")\n",
        "  tmp_world_df['Winner_Count'] = tmp_world_df['Winner_Count'].fillna(0)\n",
        "  winning_country_year_geometry_df.append(tmp_world_df) #Appending the winner count to the world dataframe using the newly created column and then appending them to a list\n",
        "unavailable_Country_codes =set(unavailable_Country_codes)\n",
        "if len(unavailable_Country_codes) > 0:\n",
        "  print(\"Unavailable country codes\",unavailable_Country_codes)\n",
        "\n",
        "output_path = '/content/ATP_matches_Visualisation/maps'\n",
        "try:\n",
        "  os.mkdir(output_path)\n",
        "except:\n",
        "  print(\"unable to create output directory \"+output_path)\n",
        "\n",
        "images = []\n",
        "\n",
        "vmin, vmax = 0, 370\n",
        "for e in range(len(winning_country_year_geometry_df)):\n",
        "    \n",
        "    # create map, UDPATE: added plt.Normalize to keep the legend range the same for all maps\n",
        "    fig = winning_country_year_geometry_df[e].plot(column='Winner_Count', cmap='Blues', figsize=(10,10), linewidth=0.8, edgecolor='0.8', vmin=vmin, vmax=vmax,\n",
        "legend=True, norm=plt.Normalize(vmin=vmin, vmax=vmax), legend_kwds={'shrink': 0.5})\n",
        "    \n",
        "   \n",
        "    # remove axis of chart\n",
        "    fig.axis('off')\n",
        "    \n",
        "    # add a title\n",
        "    fig.set_title('Losers of ATP matches', \\\n",
        "              fontdict={'fontsize': '18',\n",
        "                         'fontweight' : '3'})\n",
        "    fig.annotate(year_key[e],\n",
        "            xy=(0.1, .35), xycoords='figure fraction',\n",
        "            horizontalalignment='left', verticalalignment='top',\n",
        "            fontsize=18)\n",
        "    # this will save the figure as a high-res png in the output path. you can also save as svg if you prefer.\n",
        "    filepath = os.path.join(output_path, str(year_key[e])+'_ATP_losers.png')\n",
        "    chart = fig.get_figure()\n",
        "    chart.savefig(filepath, dpi=300, transparent=True)\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "for e in range(len(winning_country_year_geometry_df)):\n",
        "  im = Image.open(os.path.join(output_path, str(year_key[e])+'_ATP_losers.png'))\n",
        "  images.append(im)\n",
        "\n",
        "# creating the GIF\n",
        "images[0].save(output_path+'/ATP_matches_losers.gif',\n",
        "               save_all=True, append_images=images[1:], optimize=True, duration=800, loop=0)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmrYoOgVzgeM"
      },
      "source": [
        "#Standarding...........\n",
        "show_gif('/content/ATP_matches_Visualisation/maps/ATP_matches_losers.gif')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2XYLJ4D8kB0"
      },
      "source": [
        "# Total players in a country"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZHeDEo-YxNo"
      },
      "source": [
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "country_dict = defaultdict(set)\n",
        "for k, g in tennis_df.groupby([\"winner_name\", \"winner_ioc\"]):\n",
        "    country_dict[k[1]].add(k[0])\n",
        "for k, g in tennis_df.groupby([\"loser_name\", \"loser_ioc\"]):\n",
        "    country_dict[k[1]].add(k[0])\n",
        "out = [[k, len(country_dict[k])]for k in country_dict]\n",
        "player_count = pd.DataFrame(out, columns=[\"country\",\"no_players\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9dlFvoU8Mdp"
      },
      "source": [
        "# Winning Count - Normalised"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOeXnT6KN6Yo"
      },
      "source": [
        "\n",
        "\n",
        "winning_country_year_df=[] #We will have seperate dataframe for every year, all dataframe to be stored in this list\n",
        "year_key = {}\n",
        "count = 0\n",
        "\n",
        "for year in set(list(tennis_df['year'])): #Looping through countries\n",
        "    tmp_list = []\n",
        "    country_dict = defaultdict(set)\n",
        "    for k, g in tennis_df[tennis_df['year'] == year].groupby([\"winner_name\", \"winner_ioc\"]):\n",
        "        country_dict[k[1]].add(k[0])\n",
        "    out = [[k, len(country_dict[k])]for k in country_dict]\n",
        "    winning_country_year_df.append(pd.DataFrame(out, columns=[\"Country\",\"Winner_Count\"]))\n",
        "    year_key[count] = year  #Creating index to year dictionary for future reference\n",
        "    count+=1\n",
        "\n",
        "for e in range(len(winning_country_year_df)):\n",
        "  for country in list(winning_country_year_df[e]['Country']):\n",
        "    winning_country_year_df[e].loc[winning_country_year_df[e]['Country'] == country,'Winner_Count']/=np.array(player_count[player_count['country']==country]['no_players'])[0]\n",
        "    #break\n",
        "  #break\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G17dJ_hDaoG9",
        "outputId": "fa5f9c9d-0e00-4279-8c5d-4335113bc6c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "'''winning_country_year_df=[] #We will have seperate dataframe for every year, all dataframe to be stored in this list\n",
        "year_key = {}\n",
        "count = 0\n",
        "\n",
        "for year in set(list(tennis_df['year'])): #Looping through countries\n",
        "    tmp_list = []\n",
        "    for country in set(list(tennis_df[tennis_df['year'] == year]['winner_ioc'])): #Looping through years\n",
        "      if country != None:\n",
        "        #print(np.array(player_count[player_count['country']==country]['no_players'])[0])\n",
        "        #print(len(tennis_df[(tennis_df['winner_ioc'] == country) & (tennis_df['year'] == year)]))\n",
        "        #print(\"-------------------------------\")\n",
        "        tmp_list.append([country,len(tennis_df[(tennis_df['winner_ioc'] == country) & (tennis_df['year'] == year)]) /np.array(player_count[player_count['country']==country]['no_players'])[0] ]) #Addding country name and number of winners\n",
        "    winning_country_year_df.append(pd.DataFrame(tmp_list,columns=['Country','Winner_Count'])) #converting to a dataframe and storing to list\n",
        "    year_key[count] = year  #Creating index to year dictionary for future reference\n",
        "    count+=1'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'winning_country_year_df=[] #We will have seperate dataframe for every year, all dataframe to be stored in this list\\nyear_key = {}\\ncount = 0\\n\\nfor year in set(list(tennis_df[\\'year\\'])): #Looping through countries\\n    tmp_list = []\\n    for country in set(list(tennis_df[tennis_df[\\'year\\'] == year][\\'winner_ioc\\'])): #Looping through years\\n      if country != None:\\n        #print(np.array(player_count[player_count[\\'country\\']==country][\\'no_players\\'])[0])\\n        #print(len(tennis_df[(tennis_df[\\'winner_ioc\\'] == country) & (tennis_df[\\'year\\'] == year)]))\\n        #print(\"-------------------------------\")\\n        tmp_list.append([country,len(tennis_df[(tennis_df[\\'winner_ioc\\'] == country) & (tennis_df[\\'year\\'] == year)]) /np.array(player_count[player_count[\\'country\\']==country][\\'no_players\\'])[0] ]) #Addding country name and number of winners\\n    winning_country_year_df.append(pd.DataFrame(tmp_list,columns=[\\'Country\\',\\'Winner_Count\\'])) #converting to a dataframe and storing to list\\n    year_key[count] = year  #Creating index to year dictionary for future reference\\n    count+=1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjxNj9rJ8rZJ"
      },
      "source": [
        "#\n",
        "winning_country_year_geometry_df = [] #List to hold dataframe for every year. Each dataframe will be an extension of world df with winner count as additional column\n",
        "\n",
        "#Below are some hard coded values to map with the ones in world dataframe\n",
        "#\n",
        "unavailable_Country_codes = [] #To save country codes which are not available\n",
        "\n",
        "#AHO belong to netherlands antilles, which is not available in world dataframe hence mapping it to USA\n",
        "#GUM belong to Guam, which is not available in world dataframe hence mapping it to USA\n",
        "#AND belong to Andorra, which is not available in world dataframe hence mapping it to spain\n",
        "#BAR belong to Barbados, which is not available in world dataframe hence mapping it to PRI\n",
        "#HKG belong to Hong Kong, which is not available in world dataframe hence mapping it to CHINA - CHN\n",
        "#MHL belong to Marshall Islands, which is not available in world dataframe hence mapping it to USA\n",
        "#SAM belong to Samoa, which is not available in world dataframe hence mapping it to USA\n",
        "#COK belong to cook islands, which is not available in world dataframe hence mapping it to NZL\n",
        "\n",
        "#Dictionary to map ATP country code to ISO country code for the ones which are tricky\n",
        "some_known_dict = {'INA':'IDN','PUR':'PRI','ESA':'EST','RSA':'ZAF','MAS':'MYS','NED':'NLD','TPE':'TWN','SUI':'CHE','AHO':'USA'\\\n",
        "                   ,'AND':'ESP','CRC':'CRI','GUM':'USA','HKG':'CHN','IRI':'IRN','MHL':'USA','SAM':'USA','BAR':'PRI','UAE':'ARE',\\\n",
        "                   'NGR':'NGA','COK':'NZL'}\n",
        "\n",
        "for e in range(len(winning_country_year_df)):\n",
        "  geom_col = []  #We want to create a new column which will have the iso_a3 country code for a given country\n",
        "  for each_count in list(winning_country_year_df[e]['Country']): #each_count is each_country\n",
        "    subsetdf = world[world['iso_a3'] == each_count] #Checking is the ATP country code is same as iso country code\n",
        "    if len(subsetdf) == 1:\n",
        "      geom_col.append(subsetdf.iloc[0]['iso_a3'])  #Appending the iso country code\n",
        "    else:\n",
        "      subsetdf = world[world['new_name'] == each_count]  #We created a new columns with the first 3 letters of every country. Checking to see if it matches ATP code\n",
        "      if len(subsetdf) > 0:\n",
        "        geom_col.append(subsetdf.iloc[0]['iso_a3']) #In case of a match, Appending its iso country code\n",
        "      else:\n",
        "        try:\n",
        "          subsetdf = world[world['iso_a3'] == some_known_dict[each_count]] #Else checking in out dictonary for the ATP country code\n",
        "          if len(subsetdf) > 0:\n",
        "            geom_col.append(some_known_dict[each_count])  #In case of a match appending its iso_a3 country code\n",
        "          else:\n",
        "            print(each_count,\" could not be found\")  #Else printing to check manually\n",
        "            unavailable_Country_codes.append(each_count)\n",
        "            print(e)\n",
        "            geom_col.append(\"\")\n",
        "        except:  #Else printing to check manually\n",
        "          print(each_count,\" could not be found\")\n",
        "          unavailable_Country_codes.append(each_count)\n",
        "          print(e)\n",
        "          geom_col.append(\"\")\n",
        "  winning_country_year_df[e]['matching_col'] = geom_col  #Appending the new column to the dataframe\n",
        "  tmp_world_df = world.merge(winning_country_year_df[e], how='left', left_on=\"iso_a3\", right_on=\"matching_col\")\n",
        "  tmp_world_df['Winner_Count'] = tmp_world_df['Winner_Count'].fillna(0)\n",
        "  winning_country_year_geometry_df.append(tmp_world_df) #Appending the winner count to the world dataframe using the newly created column and then appending them to a list\n",
        "unavailable_Country_codes =set(unavailable_Country_codes)\n",
        "if len(unavailable_Country_codes) > 0:\n",
        "  print(\"Unavailable country codes\",unavailable_Country_codes)\n",
        "  \n",
        "output_path = '/content/ATP_matches_Visualisation/maps'\n",
        "try:\n",
        "  os.mkdir(output_path)\n",
        "except:\n",
        "  print(\"unable to create output directory \"+output_path)\n",
        "\n",
        "images = []\n",
        "\n",
        "vmin, vmax = 0, 1\n",
        "for e in range(len(winning_country_year_geometry_df)):\n",
        "    \n",
        "    # create map, UDPATE: added plt.Normalize to keep the legend range the same for all maps\n",
        "    fig = winning_country_year_geometry_df[e].plot(column='Winner_Count', cmap='Blues', figsize=(10,10), linewidth=0.8, edgecolor='0.8', vmin=vmin, vmax=vmax,\n",
        "legend=True, norm=plt.Normalize(vmin=vmin, vmax=vmax), legend_kwds={'shrink': 0.5})\n",
        "    \n",
        "   \n",
        "    # remove axis of chart\n",
        "    fig.axis('off')\n",
        "    \n",
        "    # add a title\n",
        "    fig.set_title('Winners (to total players) of ATP matches', \\\n",
        "              fontdict={'fontsize': '18',\n",
        "                         'fontweight' : '3'})\n",
        "    fig.annotate(year_key[e],\n",
        "            xy=(0.1, .35), xycoords='figure fraction',\n",
        "            horizontalalignment='left', verticalalignment='top',\n",
        "            fontsize=18)\n",
        "    # this will save the figure as a high-res png in the output path. you can also save as svg if you prefer.\n",
        "    filepath = os.path.join(output_path, str(year_key[e])+'_ATP_winners_ratio.png')\n",
        "    chart = fig.get_figure()\n",
        "    chart.savefig(filepath, dpi=300, transparent=True)\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "for e in range(len(winning_country_year_geometry_df)):\n",
        "  im = Image.open(os.path.join(output_path, str(year_key[e])+'_ATP_winners_ratio.png'))\n",
        "  images.append(im)\n",
        "\n",
        "# creating the GIF\n",
        "images[0].save(output_path+'/ATP_matches_winners_noramlized.gif',\n",
        "               save_all=True, append_images=images[1:], optimize=True, duration=800, loop=0)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "um5gVAsp_CdC"
      },
      "source": [
        "show_gif('/content/ATP_matches_Visualisation/maps/ATP_matches_winners_noramlized.gif')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57s8cvgN_POH"
      },
      "source": [
        "# Losers Count - Normalised"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsnFtnYn_T-x"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "winning_country_year_df=[] #We will have seperate dataframe for every year, all dataframe to be stored in this list\n",
        "year_key = {}\n",
        "count = 0\n",
        "\n",
        "for year in set(list(tennis_df['year'])): #Looping through countries\n",
        "    tmp_list = []\n",
        "    country_dict = defaultdict(set)\n",
        "    for k, g in tennis_df[tennis_df['year'] == year].groupby([\"loser_name\", \"loser_ioc\"]):\n",
        "        country_dict[k[1]].add(k[0])\n",
        "    out = [[k, len(country_dict[k])]for k in country_dict]\n",
        "    winning_country_year_df.append(pd.DataFrame(out, columns=[\"Country\",\"Loser_Count\"]))\n",
        "    year_key[count] = year  #Creating index to year dictionary for future reference\n",
        "    count+=1\n",
        "\n",
        "for e in range(len(winning_country_year_df)):\n",
        "  for country in list(winning_country_year_df[e]['Country']):\n",
        "    winning_country_year_df[e].loc[winning_country_year_df[e]['Country'] == country,'Loser_Count']/=np.array(player_count[player_count['country']==country]['no_players'])[0]\n",
        "    #break\n",
        "  #break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "winning_country_year_geometry_df = [] #List to hold dataframe for every year. Each dataframe will be an extension of world df with winner count as additional column\n",
        "\n",
        "#Below are some hard coded values to map with the ones in world dataframe\n",
        "#\n",
        "unavailable_Country_codes = [] #To save country codes which are not available\n",
        "\n",
        "#AHO belong to netherlands antilles, which is not available in world dataframe hence mapping it to USA\n",
        "#GUM belong to Guam, which is not available in world dataframe hence mapping it to USA\n",
        "#AND belong to Andorra, which is not available in world dataframe hence mapping it to spain\n",
        "#BAR belong to Barbados, which is not available in world dataframe hence mapping it to PRI\n",
        "#HKG belong to Hong Kong, which is not available in world dataframe hence mapping it to CHINA - CHN\n",
        "#MHL belong to Marshall Islands, which is not available in world dataframe hence mapping it to USA\n",
        "#SAM belong to Samoa, which is not available in world dataframe hence mapping it to USA\n",
        "#COK belong to cook islands, which is not available in world dataframe hence mapping it to NZL\n",
        "\n",
        "#Dictionary to map ATP country code to ISO country code for the ones which are tricky\n",
        "some_known_dict = {'INA':'IDN','PUR':'PRI','ESA':'EST','RSA':'ZAF','MAS':'MYS','NED':'NLD','TPE':'TWN','SUI':'CHE','AHO':'USA'\\\n",
        "                   ,'AND':'ESP','CRC':'CRI','GUM':'USA','HKG':'CHN','IRI':'IRN','MHL':'USA','SAM':'USA','BAR':'PRI','UAE':'ARE',\\\n",
        "                   'NGR':'NGA','COK':'NZL'}\n",
        "\n",
        "for e in range(len(winning_country_year_df)):\n",
        "  geom_col = []  #We want to create a new column which will have the iso_a3 country code for a given country\n",
        "  for each_count in list(winning_country_year_df[e]['Country']): #each_count is each_country\n",
        "    subsetdf = world[world['iso_a3'] == each_count] #Checking is the ATP country code is same as iso country code\n",
        "    if len(subsetdf) == 1:\n",
        "      geom_col.append(subsetdf.iloc[0]['iso_a3'])  #Appending the iso country code\n",
        "    else:\n",
        "      subsetdf = world[world['new_name'] == each_count]  #We created a new columns with the first 3 letters of every country. Checking to see if it matches ATP code\n",
        "      if len(subsetdf) > 0:\n",
        "        geom_col.append(subsetdf.iloc[0]['iso_a3']) #In case of a match, Appending its iso country code\n",
        "      else:\n",
        "        try:\n",
        "          subsetdf = world[world['iso_a3'] == some_known_dict[each_count]] #Else checking in out dictonary for the ATP country code\n",
        "          if len(subsetdf) > 0:\n",
        "            geom_col.append(some_known_dict[each_count])  #In case of a match appending its iso_a3 country code\n",
        "          else:\n",
        "            print(each_count,\" could not be found\")  #Else printing to check manually\n",
        "            unavailable_Country_codes.append(each_count)\n",
        "            print(e)\n",
        "            geom_col.append(\"\")\n",
        "        except:  #Else printing to check manually\n",
        "          print(each_count,\" could not be found\")\n",
        "          unavailable_Country_codes.append(each_count)\n",
        "          print(e)\n",
        "          geom_col.append(\"\")\n",
        "  winning_country_year_df[e]['matching_col'] = geom_col  #Appending the new column to the dataframe\n",
        "  tmp_world_df = world.merge(winning_country_year_df[e], how='left', left_on=\"iso_a3\", right_on=\"matching_col\")\n",
        "  tmp_world_df['Loser_Count'] = tmp_world_df['Loser_Count'].fillna(0)\n",
        "  winning_country_year_geometry_df.append(tmp_world_df) #Appending the winner count to the world dataframe using the newly created column and then appending them to a list\n",
        "unavailable_Country_codes =set(unavailable_Country_codes)\n",
        "if len(unavailable_Country_codes) > 0:\n",
        "  print(\"Unavailable country codes\",unavailable_Country_codes)\n",
        "  \n",
        "output_path = '/content/ATP_matches_Visualisation/maps'\n",
        "try:\n",
        "  os.mkdir(output_path)\n",
        "except:\n",
        "  print(\"unable to create output directory \"+output_path)\n",
        "\n",
        "images = []\n",
        "\n",
        "vmin, vmax = 0, 1\n",
        "for e in range(len(winning_country_year_geometry_df)):\n",
        "    \n",
        "    # create map, UDPATE: added plt.Normalize to keep the legend range the same for all maps\n",
        "    fig = winning_country_year_geometry_df[e].plot(column='Loser_Count', cmap='Blues', figsize=(10,10), linewidth=0.8, edgecolor='0.8', vmin=vmin, vmax=vmax,\n",
        "legend=True, norm=plt.Normalize(vmin=vmin, vmax=vmax), legend_kwds={'shrink': 0.5})\n",
        "    \n",
        "   \n",
        "    # remove axis of chart\n",
        "    fig.axis('off')\n",
        "    \n",
        "    # add a title\n",
        "    fig.set_title('Losers (to total players)of ATP matches', \\\n",
        "              fontdict={'fontsize': '18',\n",
        "                         'fontweight' : '3'})\n",
        "    fig.annotate(year_key[e],\n",
        "            xy=(0.1, .35), xycoords='figure fraction',\n",
        "            horizontalalignment='left', verticalalignment='top',\n",
        "            fontsize=18)\n",
        "    # this will save the figure as a high-res png in the output path. you can also save as svg if you prefer.\n",
        "    filepath = os.path.join(output_path, str(year_key[e])+'_ATP_losers_ratio.png')\n",
        "    chart = fig.get_figure()\n",
        "    chart.savefig(filepath, dpi=300, transparent=True)\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "for e in range(len(winning_country_year_geometry_df)):\n",
        "  im = Image.open(os.path.join(output_path, str(year_key[e])+'_ATP_losers_ratio.png'))\n",
        "  images.append(im)\n",
        "\n",
        "# creating the GIF\n",
        "images[0].save(output_path+'/ATP_matches_losers_noramlized.gif',\n",
        "               save_all=True, append_images=images[1:], optimize=True, duration=800, loop=0)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YfdrN6f_c4D"
      },
      "source": [
        "show_gif('/content/ATP_matches_Visualisation/maps/ATP_matches_losers_noramlized.gif')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-kg6lwBzse9"
      },
      "source": [
        "# References\n",
        "\n",
        "https://towardsdatascience.com/how-to-make-a-gif-map-using-python-geopandas-and-matplotlib-cd8827cefbc8\n",
        "\n",
        "https://medium.com/@maeliza.seymour/animated-choropleth-map-with-plotly-covid-19-use-case-7a13244d0ee3\n",
        "\n",
        "https://www.wikiwand.com/en/List_of_IOC_country_codes - ATP country codes"
      ]
    }
  ]
}